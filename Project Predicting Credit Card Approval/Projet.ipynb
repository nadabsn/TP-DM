{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e1f4164",
   "metadata": {},
   "source": [
    "### <h3 ><center>Projet Data Mining:</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0549ab3a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Predicting Credit Card Approval</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e4fda",
   "metadata": {},
   "source": [
    "<h3><center>Réalisé par: Hazem Mejri & Nada Ben Slimen</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597d9257",
   "metadata": {},
   "source": [
    "## I- Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d51eac",
   "metadata": {},
   "source": [
    "Les banques reçoivent beaucoup de demandes de cartes de crédit. Beaucoup d'entre eux sont rejetés pour de nombreuses raisons, comme des soldes de prêts élevés, de faibles niveaux de revenus ou un trop grand nombre de demandes de renseignements sur le rapport de crédit d'un individu. \n",
    "L'analyse manuelle de ces applications est banale, sujette aux erreurs et prend du temps. Heureusement, cette tâche peut être automatisée grâce à la puissance de l'apprentissage automatique et à peu près toutes les banques appliquent cette méthode. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7871af30",
   "metadata": {},
   "source": [
    "## II- Objectif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87529915",
   "metadata": {},
   "source": [
    "Nous allons créer un prédicteur automatique d'approbation de carte de crédit en utilisant des techniques d'apprentissage automatique, tout comme le font les vraies banques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf0a9de",
   "metadata": {},
   "source": [
    "## III- Les étapes à suivre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4c4eb9",
   "metadata": {},
   "source": [
    "* Tout d'abord, nous allons commencer par charger et visualiser l'ensemble de données: *Nous verrons que l'ensemble de données a un mélange de caractéristiques numériques et non numériques, qu'il contient des \n",
    "valeurs de différentes plages, plus qu'il contient un certain nombre d'entrées manquantes.*\n",
    "* Nous devrons prétraiter l'ensemble de données pour nous assurer que le modèle d'apprentissage automatique que nous choisissons peut faire de bonnes prédictions.\n",
    "* Une fois nos données en bon état, nous procéderons à une analyse exploratoire des données pour construire nos intuitions.\n",
    "* Enfin, nous construirons un modèle d'apprentissage automatique qui peut prédire si la demande de carte de crédit d'un individu sera acceptée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f101be70",
   "metadata": {},
   "source": [
    "### 1- Chargement et visualisation de l'ensemble de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39967e81",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52c7cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge rise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d79903ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_apps = pd.read_csv('datasets/cc_approvals.data', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b26561",
   "metadata": {},
   "source": [
    "<p style='background :yellow'> Voici le <code>head()</code> du dataset  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae18ea9f",
   "metadata": {},
   "source": [
    "cc_apps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "216e0bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               2           7          10             14\n",
      "count  690.000000  690.000000  690.00000     690.000000\n",
      "mean     4.758725    2.223406    2.40000    1017.385507\n",
      "std      4.978163    3.346513    4.86294    5210.102598\n",
      "min      0.000000    0.000000    0.00000       0.000000\n",
      "25%      1.000000    0.165000    0.00000       0.000000\n",
      "50%      2.750000    1.000000    0.00000       5.000000\n",
      "75%      7.207500    2.625000    3.00000     395.500000\n",
      "max     28.000000   28.500000   67.00000  100000.000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cc_apps_description = cc_apps.describe()\n",
    "print(cc_apps_description)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32ddf689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       690 non-null    object \n",
      " 1   1       690 non-null    object \n",
      " 2   2       690 non-null    float64\n",
      " 3   3       690 non-null    object \n",
      " 4   4       690 non-null    object \n",
      " 5   5       690 non-null    object \n",
      " 6   6       690 non-null    object \n",
      " 7   7       690 non-null    float64\n",
      " 8   8       690 non-null    object \n",
      " 9   9       690 non-null    object \n",
      " 10  10      690 non-null    int64  \n",
      " 11  11      690 non-null    object \n",
      " 12  12      690 non-null    object \n",
      " 13  13      690 non-null    object \n",
      " 14  14      690 non-null    int64  \n",
      " 15  15      690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.4+ KB\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cc_apps_info = cc_apps.info()\n",
    "print(cc_apps_info)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a317579",
   "metadata": {},
   "source": [
    "<p style='background :yellow'> => On remarque qu'il y a 4 features numérique et 12 non numériques</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17614ce9",
   "metadata": {},
   "source": [
    "### 2- Handling the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589cbccd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0      1       2  3  4   5   6      7  8  9   10 11 12     13   14 15\n",
      "673  ?  29.50   2.000  y  p   e   h  2.000  f  f   0  f  g  00256   17  -\n",
      "674  a  37.33   2.500  u  g   i   h  0.210  f  f   0  f  g  00260  246  -\n",
      "675  a  41.58   1.040  u  g  aa   v  0.665  f  f   0  f  g  00240  237  -\n",
      "676  a  30.58  10.665  u  g   q   h  0.085  f  t  12  t  g  00129    3  -\n",
      "677  b  19.42   7.250  u  g   m   v  0.040  f  t   1  f  g  00100    1  -\n",
      "678  a  17.92  10.210  u  g  ff  ff  0.000  f  f   0  f  g  00000   50  -\n",
      "679  a  20.08   1.250  u  g   c   v  0.000  f  f   0  f  g  00000    0  -\n",
      "680  b  19.50   0.290  u  g   k   v  0.290  f  f   0  f  g  00280  364  -\n",
      "681  b  27.83   1.000  y  p   d   h  3.000  f  f   0  f  g  00176  537  -\n",
      "682  b  17.08   3.290  u  g   i   v  0.335  f  f   0  t  g  00140    2  -\n",
      "683  b  36.42   0.750  y  p   d   v  0.585  f  f   0  f  g  00240    3  -\n",
      "684  b  40.58   3.290  u  g   m   v  3.500  f  f   0  t  s  00400    0  -\n",
      "685  b  21.08  10.085  y  p   e   h  1.250  f  f   0  f  g  00260    0  -\n",
      "686  a  22.67   0.750  u  g   c   v  2.000  f  t   2  t  g  00200  394  -\n",
      "687  a  25.25  13.500  y  p  ff  ff  2.000  f  t   1  t  g  00200    1  -\n",
      "688  b  17.92   0.205  u  g  aa   v  0.040  f  f   0  f  g  00280  750  -\n",
      "689  b  35.00   3.375  u  g   c   h  8.290  f  f   0  t  g  00000    0  -\n"
     ]
    }
   ],
   "source": [
    "print(cc_apps.tail(17))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dc5d51",
   "metadata": {},
   "source": [
    "<p style='background :yellow'>=> On remarque que notre dataset contient des valeurs manquantes donc pour le moment on va les remplacer par <code>nan</code>  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27022a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0      1       2  3  4   5   6      7  8  9   10 11 12     13   14 15\n",
      "673  NaN  29.50   2.000  y  p   e   h  2.000  f  f   0  f  g  00256   17  -\n",
      "674    a  37.33   2.500  u  g   i   h  0.210  f  f   0  f  g  00260  246  -\n",
      "675    a  41.58   1.040  u  g  aa   v  0.665  f  f   0  f  g  00240  237  -\n",
      "676    a  30.58  10.665  u  g   q   h  0.085  f  t  12  t  g  00129    3  -\n",
      "677    b  19.42   7.250  u  g   m   v  0.040  f  t   1  f  g  00100    1  -\n",
      "678    a  17.92  10.210  u  g  ff  ff  0.000  f  f   0  f  g  00000   50  -\n",
      "679    a  20.08   1.250  u  g   c   v  0.000  f  f   0  f  g  00000    0  -\n",
      "680    b  19.50   0.290  u  g   k   v  0.290  f  f   0  f  g  00280  364  -\n",
      "681    b  27.83   1.000  y  p   d   h  3.000  f  f   0  f  g  00176  537  -\n",
      "682    b  17.08   3.290  u  g   i   v  0.335  f  f   0  t  g  00140    2  -\n",
      "683    b  36.42   0.750  y  p   d   v  0.585  f  f   0  f  g  00240    3  -\n",
      "684    b  40.58   3.290  u  g   m   v  3.500  f  f   0  t  s  00400    0  -\n",
      "685    b  21.08  10.085  y  p   e   h  1.250  f  f   0  f  g  00260    0  -\n",
      "686    a  22.67   0.750  u  g   c   v  2.000  f  t   2  t  g  00200  394  -\n",
      "687    a  25.25  13.500  y  p  ff  ff  2.000  f  t   1  t  g  00200    1  -\n",
      "688    b  17.92   0.205  u  g  aa   v  0.040  f  f   0  f  g  00280  750  -\n",
      "689    b  35.00   3.375  u  g   c   h  8.290  f  f   0  t  g  00000    0  -\n"
     ]
    }
   ],
   "source": [
    "# Replace the '?'s with NaN\n",
    "cc_apps = cc_apps.replace('?', np.nan)\n",
    "\n",
    "# Inspect the missing values again\n",
    "print(cc_apps.tail(17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a17e631e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     12\n",
      "1     12\n",
      "2      0\n",
      "3      6\n",
      "4      6\n",
      "5      9\n",
      "6      9\n",
      "7      0\n",
      "8      0\n",
      "9      0\n",
      "10     0\n",
      "11     0\n",
      "12     0\n",
      "13    13\n",
      "14     0\n",
      "15     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of NaNs in the dataset to verify\n",
    "print(cc_apps.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc0133",
   "metadata": {},
   "source": [
    "<p style='background :yellow'> Les colonnes 2-7-10-14 sont de type Int64 et float64 , on va leur appliqué la methode <code>mean()</code> pour  remplir les valeurs manquantes par une valeur moyenne  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3476f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     12\n",
      "1     12\n",
      "2      0\n",
      "3      6\n",
      "4      6\n",
      "5      9\n",
      "6      9\n",
      "7      0\n",
      "8      0\n",
      "9      0\n",
      "10     0\n",
      "11     0\n",
      "12     0\n",
      "13    13\n",
      "14     0\n",
      "15     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Impute the missing values with mean imputation\n",
    "cc_apps.loc[[2,7,10,14]].fillna(np.mean, inplace=True)\n",
    "\n",
    "# Count the number of NaNs in the dataset to verify\n",
    "print(cc_apps.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8dc164",
   "metadata": {},
   "source": [
    "<p style='background :yellow'> Pour les colonnes de type <code>object</code> on doit les remplir par les valeurs les plus fréquentes </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caf51726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each column of cc_apps\n",
    "for col in list(cc_apps):\n",
    "    # Check if the column is of object type\n",
    "    if cc_apps[col].dtypes == 'object':\n",
    "        # Impute with the most frequent value\n",
    "        cc_apps = cc_apps.fillna(cc_apps[col].value_counts().index[0])\n",
    "\n",
    "# Count the number of NaNs in the dataset and print the counts to verify   \n",
    "print(cc_apps.isna().sum())       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2264756a",
   "metadata": {},
   "source": [
    "<p style='background :yellow'> => Il n'y a plus de valeurs manquantes </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc87c6a",
   "metadata": {},
   "source": [
    "### 2- Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc30d7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate LabelEncoder\n",
    "le = LabelEncoder()\n",
    "# Iterate over all the values of each column and extract their dtypes\n",
    "for col in cc_apps.columns.values:\n",
    "    # Compare if the dtype is object\n",
    "    if cc_apps[col].dtypes=='object':\n",
    "    # Use LabelEncoder to do the numeric transformation\n",
    "        cc_apps[col]=le.fit_transform(cc_apps[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9e8c6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       690 non-null    int32  \n",
      " 1   1       690 non-null    int32  \n",
      " 2   2       690 non-null    float64\n",
      " 3   3       690 non-null    int32  \n",
      " 4   4       690 non-null    int32  \n",
      " 5   5       690 non-null    int32  \n",
      " 6   6       690 non-null    int32  \n",
      " 7   7       690 non-null    float64\n",
      " 8   8       690 non-null    int32  \n",
      " 9   9       690 non-null    int32  \n",
      " 10  10      690 non-null    int64  \n",
      " 11  11      690 non-null    int32  \n",
      " 12  12      690 non-null    int32  \n",
      " 13  13      690 non-null    int32  \n",
      " 14  14      690 non-null    int64  \n",
      " 15  15      690 non-null    int32  \n",
      "dtypes: float64(2), int32(12), int64(2)\n",
      "memory usage: 54.0 KB\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cc_apps_info = cc_apps.info()\n",
    "print(cc_apps_info)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0f36d0",
   "metadata": {},
   "source": [
    "<p  style='background :yellow' > Aprés le remplissage des valeurs manquantes et la conversion des colonnes non-numeriques au numeriques, on obtient la dataset suivante  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "598e7c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "      <td>4.460</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1.540</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>5.625</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1      2   3   4   5   6     7   8   9   10  11  12  13   14  15\n",
       "0   1  156  0.000   2   1  13   8  1.25   1   1   1   0   0  68    0   0\n",
       "1   0  328  4.460   2   1  11   4  3.04   1   1   6   0   0  11  560   0\n",
       "2   0   89  0.500   2   1  11   4  1.50   1   0   0   0   0  96  824   0\n",
       "3   1  125  1.540   2   1  13   8  3.75   1   1   5   1   0  31    3   0\n",
       "4   1   43  5.625   2   1  13   8  1.71   1   0   0   0   2  37    0   0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_apps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9e845b",
   "metadata": {},
   "source": [
    "<p  style='background :yellow'> On doit maintenant diviser la dataset en train set et test set  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2811ba2b",
   "metadata": {},
   "source": [
    "### 3- Splitting the dataset into train and test sets¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f0960e",
   "metadata": {},
   "source": [
    "<p  style='background :yellow'> Les features tels que *DriversLicense* et *ZipCode* ne sont pas aussi importantes que les autres features afin de prédire les approbations de carte de crédit. Nous devrions les supprimer pour concevoir notre modèle d'apprentissage automatique avec le meilleur ensemble de features.  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acab3338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the features 11 and 13 and convert the DataFrame to a NumPy array\n",
    "cc_apps = cc_apps.drop([11,13], axis=1)\n",
    "cc_apps = cc_apps.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd179b3",
   "metadata": {},
   "source": [
    "<p  style='background :yellow'> Maintenant, nous allons diviser nos données en ensemble de trains et ensemble de test pour préparer nos données pour deux phases différentes de la modélisation de l'apprentissage automatique : le training et le test.   </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8376afec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.000e+00 1.560e+02 0.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [0.000e+00 3.280e+02 4.460e+00 ... 0.000e+00 5.600e+02 0.000e+00]\n",
      " [0.000e+00 8.900e+01 5.000e-01 ... 0.000e+00 8.240e+02 0.000e+00]\n",
      " ...\n",
      " [0.000e+00 9.700e+01 1.350e+01 ... 0.000e+00 1.000e+00 1.000e+00]\n",
      " [1.000e+00 2.000e+01 2.050e-01 ... 0.000e+00 7.500e+02 1.000e+00]\n",
      " [1.000e+00 1.970e+02 3.375e+00 ... 0.000e+00 0.000e+00 1.000e+00]]\n",
      "(462, 12) (462,)\n",
      "(228, 12) (228,)\n"
     ]
    }
   ],
   "source": [
    "# Segregate features and labels into separate variables\n",
    "X,y = cc_apps[:,0:12] , cc_apps[:,13]\n",
    "print(cc_apps)\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                y,\n",
    "                                test_size=0.33,\n",
    "                                random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d47b9e",
   "metadata": {},
   "source": [
    "<p  style='background :yellow'> Il ne nous reste qu'une dernière étape de preprocessing de scaling avant de pouvoir adapter un modèle d'apprentissage automatique aux données  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ddcc79",
   "metadata": {},
   "source": [
    "### 4- Fitting a logistic regression model to the train set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1aeccc",
   "metadata": {},
   "source": [
    "<p  style='background :yellow'>  Parmi 690 instances, il y a 383 (55,5 %) demandes qui ont été refusées et 307 (44,5 %) demandes qui ont été approuvées. Cela nous donne une référence. Un bon modèle de machine learning doit être capable de prédire avec précision l'état des applications par rapport à ces statistiques\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e209bc88",
   "metadata": {},
   "source": [
    "<p  style='background :yellow'>les modèles linéaires généralisés fonctionnent bien dans ces cas. Commençons notre modélisation d'apprentissage automatique avec un modèle de régression logistique (un modèle linéaire généralisé).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e7a457a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 12)\n",
      "(228, 12)\n"
     ]
    }
   ],
   "source": [
    "# Import MinMaxScaler\n",
    "# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX_train = scaler.fit_transform(X_train)\n",
    "rescaledX_test = scaler.fit_transform(X_test)\n",
    "\n",
    "print(rescaledX_train.shape)\n",
    "print(rescaledX_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccd1db6",
   "metadata": {},
   "source": [
    "<p  style='background :yellow'> On applique maintenant la méthode Logistic Regression sur rescaledX_train et y_train </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1223fbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Instantiate a LogisticRegression classifier with default parameter values\n",
    "logreg = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "# Fit logreg to the train set\n",
    "logreg.fit(rescaledX_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "266dae67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier:  0.8377192982456141\n",
      "[[93 10]\n",
      " [27 98]]\n"
     ]
    }
   ],
   "source": [
    "# Import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Use logreg to predict instances from the test set and store it\n",
    "y_pred = logreg.predict(rescaledX_test)\n",
    "\n",
    "# Get the accuracy score of logreg model and print it\n",
    "print(\"Accuracy of logistic regression classifier: \", accuracy_score(y_test,y_pred))\n",
    "\n",
    "# Print the confusion matrix of the logreg model\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55820748",
   "metadata": {},
   "source": [
    "<p  style='background :yellow'>Notre modèle était bon ! Il a pu donner un score de précision de près de 84%.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0222a8",
   "metadata": {},
   "source": [
    "<p  style='background :yellow'>Voyons si nous pouvons faire mieux. Nous pouvons effectuer un grid search des paramètres du modèle pour améliorer la capacité du modèle à prédire les approbations de carte de crédit.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc06319b",
   "metadata": {},
   "source": [
    "GridSearchCV essaie toutes les combinaisons des valeurs passées dans le dictionnaire et évalue le modèle pour chaque combinaison à l'aide de la méthode de Cross-validation. Par conséquent, après avoir utilisé cette fonction, nous obtenons une précision/perte pour chaque combinaison d'hyperparamètres et nous pouvons choisir celui qui offre les meilleures performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5441a5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the grid of values for tol and max_iter\n",
    "#tol: Tolerance for stopping criteria\n",
    "#max_iter: Maximum number of iterations taken for the solvers to converge.\n",
    "\n",
    "tol = [0.01,0.001,0.0001]\n",
    "max_iter = [100,150,200]\n",
    "\n",
    "# Create a dictionary where tol and max_iter are keys and the lists of their values are corresponding values\n",
    "param_grid = dict(tol = tol, max_iter = max_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7b9b87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.863651 using {'max_iter': 100, 'tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate GridSearchCV with the required parameters\n",
    "grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Use scaler to rescale X and assign it to rescaledX\n",
    "rescaledX = scaler.fit_transform(X_train)\n",
    "\n",
    "# Fit data to grid_model\n",
    "grid_model_result = grid_model.fit(rescaledX, y_train)\n",
    "\n",
    "# Summarize results\n",
    "best_score, best_params = grid_model_result.best_score_, grid_model_result.best_params_\n",
    "print(\"Best: %f using %s\" % (best_score, best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3029eb2",
   "metadata": {},
   "source": [
    "<p  style='background :yellow'> On obtient donc un modèle plus précis grace à GridSearch avec les parametres: {'max_iter': 100, 'tol': 0.01}</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dca679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
